{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82105\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "# from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import np_utils\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path=os.getcwd().replace(\"\\\\\", \"/\").replace(\"c:\", \"C:\")\n",
    "data_path=current_path+'/data/'\n",
    "model_path=current_path+\"/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=pd.read_csv(data_path+'final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>wav_id</th>\n",
       "      <th>final_label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.688733</td>\n",
       "      <td>0.665087</td>\n",
       "      <td>0.551895</td>\n",
       "      <td>0.554083</td>\n",
       "      <td>0.577122</td>\n",
       "      <td>0.589633</td>\n",
       "      <td>0.547716</td>\n",
       "      <td>0.479773</td>\n",
       "      <td>0.467628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>5.972413e-04</td>\n",
       "      <td>4.031004e-04</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>1.108980e-05</td>\n",
       "      <td>5f6892fff8fac448cc0a5b44</td>\n",
       "      <td>sadness</td>\n",
       "      <td>비싼 건 못 샀어. 알바비를 모아서 산 거거든.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.120067</td>\n",
       "      <td>0.571521</td>\n",
       "      <td>0.557885</td>\n",
       "      <td>0.552126</td>\n",
       "      <td>0.541684</td>\n",
       "      <td>0.513932</td>\n",
       "      <td>0.540703</td>\n",
       "      <td>0.624245</td>\n",
       "      <td>0.616377</td>\n",
       "      <td>0.641370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.569921e-07</td>\n",
       "      <td>6.353915e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>8.042485e-07</td>\n",
       "      <td>5f0604b9b140144dfcff01f7</td>\n",
       "      <td>sadness</td>\n",
       "      <td>내가 하고있는 일에 진도가 잘 나가지지 않아서 일하고 싶은 마음이 다 사라졌어. 무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060619</td>\n",
       "      <td>0.462079</td>\n",
       "      <td>0.468565</td>\n",
       "      <td>0.486078</td>\n",
       "      <td>0.534205</td>\n",
       "      <td>0.458072</td>\n",
       "      <td>0.390353</td>\n",
       "      <td>0.400268</td>\n",
       "      <td>0.544558</td>\n",
       "      <td>0.692785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.966622e-06</td>\n",
       "      <td>4.113252e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>4.186585e-07</td>\n",
       "      <td>5f0f24fcb140144dfcff44c6</td>\n",
       "      <td>sadness</td>\n",
       "      <td>좋은 생각이네 강남역 보다는 그 근처에 있는 한가한 공원으로 바꾸는게 나을 것 같아.\\t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056708</td>\n",
       "      <td>0.652244</td>\n",
       "      <td>0.713408</td>\n",
       "      <td>0.730681</td>\n",
       "      <td>0.730744</td>\n",
       "      <td>0.700714</td>\n",
       "      <td>0.686664</td>\n",
       "      <td>0.632844</td>\n",
       "      <td>0.579585</td>\n",
       "      <td>0.620094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>8.719081e-06</td>\n",
       "      <td>2.982148e-05</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.901741e-07</td>\n",
       "      <td>5f0122f3704f492ee12565b8</td>\n",
       "      <td>sadness</td>\n",
       "      <td>지난번에도 미뤘던 약속이야. 더 이상 미루기에는 너무 미안해.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.466003</td>\n",
       "      <td>0.363453</td>\n",
       "      <td>0.379380</td>\n",
       "      <td>0.392485</td>\n",
       "      <td>0.354566</td>\n",
       "      <td>0.348200</td>\n",
       "      <td>0.404133</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>0.672009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.572638e-06</td>\n",
       "      <td>4.523758e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5.580449e-07</td>\n",
       "      <td>5f0c741bb140144dfcff2f19</td>\n",
       "      <td>sadness</td>\n",
       "      <td>오늘이 발표날인데 나한테 연락이 없더라고. 그래서 알아봤더니 내 이름이 없대.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.142637  0.688733  0.665087  0.551895  0.554083  0.577122  0.589633   \n",
       "1  0.120067  0.571521  0.557885  0.552126  0.541684  0.513932  0.540703   \n",
       "2  0.060619  0.462079  0.468565  0.486078  0.534205  0.458072  0.390353   \n",
       "3  0.056708  0.652244  0.713408  0.730681  0.730744  0.700714  0.686664   \n",
       "4  0.056130  0.466003  0.363453  0.379380  0.392485  0.354566  0.348200   \n",
       "\n",
       "          7         8         9  ...       479           480           481  \\\n",
       "0  0.547716  0.479773  0.467628  ...  0.000592  5.972413e-04  4.031004e-04   \n",
       "1  0.624245  0.616377  0.641370  ...  0.000001  5.569921e-07  6.353915e-07   \n",
       "2  0.400268  0.544558  0.692785  ...  0.000005  4.966622e-06  4.113252e-06   \n",
       "3  0.632844  0.579585  0.620094  ...  0.000003  8.719081e-06  2.982148e-05   \n",
       "4  0.404133  0.500080  0.672009  ...  0.000003  3.572638e-06  4.523758e-06   \n",
       "\n",
       "        482       483       484           485                    wav_id  \\\n",
       "0  0.000356  0.000352  0.000134  1.108980e-05  5f6892fff8fac448cc0a5b44   \n",
       "1  0.000005  0.000009  0.000007  8.042485e-07  5f0604b9b140144dfcff01f7   \n",
       "2  0.000011  0.000011  0.000006  4.186585e-07  5f0f24fcb140144dfcff44c6   \n",
       "3  0.000080  0.000034  0.000011  4.901741e-07  5f0122f3704f492ee12565b8   \n",
       "4  0.000007  0.000011  0.000008  5.580449e-07  5f0c741bb140144dfcff2f19   \n",
       "\n",
       "   final_label                                           sentence  \n",
       "0      sadness                         비싼 건 못 샀어. 알바비를 모아서 산 거거든.  \n",
       "1      sadness  내가 하고있는 일에 진도가 잘 나가지지 않아서 일하고 싶은 마음이 다 사라졌어. 무...  \n",
       "2      sadness  좋은 생각이네 강남역 보다는 그 근처에 있는 한가한 공원으로 바꾸는게 나을 것 같아.\\t  \n",
       "3      sadness                 지난번에도 미뤘던 약속이야. 더 이상 미루기에는 너무 미안해.  \n",
       "4      sadness        오늘이 발표날인데 나한테 연락이 없더라고. 그래서 알아봤더니 내 이름이 없대.  \n",
       "\n",
       "[5 rows x 489 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class text_embedding():\n",
    "  def __init__(self, model_name):\n",
    "    self.model_name = model_name\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "  def transform(self, X):\n",
    "        embedding_model = SentenceTransformer(self.model_name)\n",
    "        embedding_vec = embedding_model.encode(X['sentence'])\n",
    "        X_val = np.concatenate((X.drop(['final_label', 'wav_id', 'sentence'], axis = 1), embedding_vec), axis = 1)\n",
    "        return X_val\n",
    "        \n",
    "def custom_model(x_train):\n",
    "  model=Sequential()\n",
    "  model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "  model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "  model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "  model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "  model.add(Dropout(0.2))\n",
    "\n",
    "  model.add(Conv1D(64, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "  model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(units=32, activation='relu'))\n",
    "  model.add(Dropout(0.3))\n",
    "\n",
    "  model.add(Dense(units=6, activation='softmax'))\n",
    "  model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "  #model.summary()\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001) #learning rate 조절\n",
    "# 선택한 모델만 다시 학습 (텍스트 + 음성)\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "model_name=\"jhgan/ko-sbert-multitask\"\n",
    "Y = final_df['final_label'].values\n",
    "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "txt_embed = text_embedding(model_name = model_name)\n",
    "X = txt_embed.transform(final_df)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, shuffle=True)\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name='jhgan/ko-sbert-multitask'\n",
    "# 정확도: 0.6979054808616638\n",
    "\n",
    "# model_name=\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
    "# 정확도: 0.6732008457183838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 63s 360ms/step - loss: 1.6743 - accuracy: 0.2843 - val_loss: 1.4422 - val_accuracy: 0.5019 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 63s 362ms/step - loss: 1.3908 - accuracy: 0.4553 - val_loss: 1.2172 - val_accuracy: 0.5618 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 64s 365ms/step - loss: 1.2733 - accuracy: 0.5072 - val_loss: 1.0895 - val_accuracy: 0.6179 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 64s 364ms/step - loss: 1.1867 - accuracy: 0.5481 - val_loss: 1.0544 - val_accuracy: 0.6305 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 66s 375ms/step - loss: 1.1503 - accuracy: 0.5587 - val_loss: 0.9932 - val_accuracy: 0.6549 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 65s 369ms/step - loss: 1.1134 - accuracy: 0.5728 - val_loss: 0.9766 - val_accuracy: 0.6611 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 64s 368ms/step - loss: 1.0900 - accuracy: 0.5836 - val_loss: 0.9719 - val_accuracy: 0.6523 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 65s 369ms/step - loss: 1.0609 - accuracy: 0.5995 - val_loss: 0.9398 - val_accuracy: 0.6721 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 64s 367ms/step - loss: 1.0370 - accuracy: 0.5994 - val_loss: 0.9250 - val_accuracy: 0.6796 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 64s 365ms/step - loss: 1.0249 - accuracy: 0.6118 - val_loss: 0.9369 - val_accuracy: 0.6627 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 64s 366ms/step - loss: 1.0081 - accuracy: 0.6126 - val_loss: 0.9119 - val_accuracy: 0.6847 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 64s 366ms/step - loss: 0.9920 - accuracy: 0.6212 - val_loss: 0.9185 - val_accuracy: 0.6775 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 64s 366ms/step - loss: 0.9709 - accuracy: 0.6282 - val_loss: 0.9271 - val_accuracy: 0.6737 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 65s 369ms/step - loss: 0.9588 - accuracy: 0.6328 - val_loss: 0.9054 - val_accuracy: 0.6780 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 0.9510 - accuracy: 0.6332 - val_loss: 0.9135 - val_accuracy: 0.6767 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 65s 372ms/step - loss: 0.9414 - accuracy: 0.6393 - val_loss: 0.9040 - val_accuracy: 0.6866 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 0.9181 - accuracy: 0.6473 - val_loss: 0.8992 - val_accuracy: 0.6901 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 65s 370ms/step - loss: 0.9256 - accuracy: 0.6422 - val_loss: 0.9210 - val_accuracy: 0.6788 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 65s 370ms/step - loss: 0.9127 - accuracy: 0.6426 - val_loss: 0.9128 - val_accuracy: 0.6786 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 65s 370ms/step - loss: 0.8937 - accuracy: 0.6534 - val_loss: 0.9097 - val_accuracy: 0.6753 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 65s 370ms/step - loss: 0.8986 - accuracy: 0.6523 - val_loss: 0.8915 - val_accuracy: 0.6907 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 65s 370ms/step - loss: 0.8627 - accuracy: 0.6691 - val_loss: 0.9207 - val_accuracy: 0.6861 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 65s 369ms/step - loss: 0.8513 - accuracy: 0.6693 - val_loss: 0.9357 - val_accuracy: 0.6864 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 0.8464 - accuracy: 0.6688 - val_loss: 0.9022 - val_accuracy: 0.7009 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 65s 372ms/step - loss: 0.8312 - accuracy: 0.6800 - val_loss: 0.9236 - val_accuracy: 0.6834 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 0.8231 - accuracy: 0.6774 - val_loss: 0.9204 - val_accuracy: 0.6874 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 66s 377ms/step - loss: 0.8195 - accuracy: 0.6767 - val_loss: 0.9111 - val_accuracy: 0.6933 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 65s 374ms/step - loss: 0.8009 - accuracy: 0.6787 - val_loss: 0.9055 - val_accuracy: 0.6850 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 65s 374ms/step - loss: 0.8006 - accuracy: 0.6848 - val_loss: 0.9126 - val_accuracy: 0.6880 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 66s 377ms/step - loss: 0.7960 - accuracy: 0.6859 - val_loss: 0.9065 - val_accuracy: 0.6944 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 65s 374ms/step - loss: 0.7765 - accuracy: 0.6938 - val_loss: 0.9433 - val_accuracy: 0.6818 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 65s 373ms/step - loss: 0.7792 - accuracy: 0.6904 - val_loss: 0.9214 - val_accuracy: 0.6877 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 0.7772 - accuracy: 0.6916 - val_loss: 0.9413 - val_accuracy: 0.6764 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 65s 374ms/step - loss: 0.7050 - accuracy: 0.7151 - val_loss: 0.9550 - val_accuracy: 0.6901 - lr: 4.0000e-04\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 66s 378ms/step - loss: 0.6776 - accuracy: 0.7189 - val_loss: 0.9585 - val_accuracy: 0.6931 - lr: 4.0000e-04\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 68s 389ms/step - loss: 0.6733 - accuracy: 0.7283 - val_loss: 0.9759 - val_accuracy: 0.7011 - lr: 4.0000e-04\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 68s 386ms/step - loss: 0.6740 - accuracy: 0.7282 - val_loss: 0.9731 - val_accuracy: 0.6971 - lr: 4.0000e-04\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 67s 385ms/step - loss: 0.6669 - accuracy: 0.7266 - val_loss: 0.9880 - val_accuracy: 0.6960 - lr: 4.0000e-04\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 67s 385ms/step - loss: 0.6619 - accuracy: 0.7335 - val_loss: 0.9671 - val_accuracy: 0.6982 - lr: 4.0000e-04\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 68s 387ms/step - loss: 0.6576 - accuracy: 0.7323 - val_loss: 0.9833 - val_accuracy: 0.6925 - lr: 4.0000e-04\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 68s 389ms/step - loss: 0.6459 - accuracy: 0.7394 - val_loss: 0.9764 - val_accuracy: 0.6939 - lr: 4.0000e-04\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 68s 386ms/step - loss: 0.6371 - accuracy: 0.7398 - val_loss: 1.0083 - val_accuracy: 0.6971 - lr: 4.0000e-04\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 68s 389ms/step - loss: 0.6432 - accuracy: 0.7393 - val_loss: 0.9891 - val_accuracy: 0.6920 - lr: 4.0000e-04\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 68s 387ms/step - loss: 0.6294 - accuracy: 0.7430 - val_loss: 0.9991 - val_accuracy: 0.6974 - lr: 4.0000e-04\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 67s 383ms/step - loss: 0.6316 - accuracy: 0.7445 - val_loss: 1.0025 - val_accuracy: 0.6904 - lr: 4.0000e-04\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 66s 380ms/step - loss: 0.6242 - accuracy: 0.7402 - val_loss: 1.0434 - val_accuracy: 0.6966 - lr: 4.0000e-04\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 65s 369ms/step - loss: 0.6231 - accuracy: 0.7441 - val_loss: 1.0114 - val_accuracy: 0.6933 - lr: 4.0000e-04\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 66s 375ms/step - loss: 0.6213 - accuracy: 0.7439 - val_loss: 1.0257 - val_accuracy: 0.6925 - lr: 4.0000e-04\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 65s 371ms/step - loss: 0.6117 - accuracy: 0.7521 - val_loss: 1.0324 - val_accuracy: 0.6917 - lr: 4.0000e-04\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 67s 383ms/step - loss: 0.6008 - accuracy: 0.7543 - val_loss: 1.0435 - val_accuracy: 0.6931 - lr: 4.0000e-04\n",
      "Pre-trained Model:  jhgan/ko-sbert-multitask\n",
      "Test Accuracy:  0.6930719614028931\n"
     ]
    }
   ],
   "source": [
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "model = custom_model(x_train)\n",
    "history=model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[rlrp])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Pre-trained Model: \", model_name)\n",
    "print(\"Test Accuracy: \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path+'my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path+'text_model_name.txt', 'w') as file:\n",
    "    file.write(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/82105/Desktop/코드/korean_emotions/model/scaler.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(encoder, model_path+'encoder.pkl')\n",
    "joblib.dump(scaler, model_path+'scaler.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
